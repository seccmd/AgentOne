#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŸºæœ¬åŠŸèƒ½æµ‹è¯•
éªŒè¯ AI Agent çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import Config
from tools import ToolManager, TerminalTool, FileTool, MathTool
from llm_client import LLMClient

def test_config():
    """æµ‹è¯•é…ç½®åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•é…ç½®åŠŸèƒ½...")
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    default_config = Config.get_model_config("openai")
    assert default_config.provider == "openai"
    print("âœ… é»˜è®¤é…ç½®æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯• Ollama é…ç½®
    ollama_config = Config.get_model_config("ollama")
    assert ollama_config.provider == "ollama"
    print("âœ… Ollama é…ç½®æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯• DeepSeek é…ç½®
    deepseek_config = Config.get_model_config("deepseek")
    assert deepseek_config.provider == "deepseek"
    print("âœ… DeepSeek é…ç½®æµ‹è¯•é€šè¿‡")
    
    print("âœ… é…ç½®åŠŸèƒ½æµ‹è¯•å®Œæˆ\n")

def test_tools():
    """æµ‹è¯•å·¥å…·åŠŸèƒ½"""
    print("ğŸ› ï¸ æµ‹è¯•å·¥å…·åŠŸèƒ½...")
    
    tool_manager = ToolManager()
    
    # æµ‹è¯•å·¥å…·åˆ—è¡¨
    tools = tool_manager.list_tools()
    assert len(tools) >= 4  # è‡³å°‘åº”è¯¥æœ‰4ä¸ªå·¥å…·
    print("âœ… å·¥å…·åˆ—è¡¨æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ•°å­¦è®¡ç®—å·¥å…·
    math_result = tool_manager.execute_tool("math", expression="2 + 3 * 4")
    assert math_result["success"] == True
    assert math_result["result"] == 14
    print("âœ… æ•°å­¦è®¡ç®—å·¥å…·æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ–‡ä»¶å·¥å…·
    file_result = tool_manager.execute_tool("file", action="exists", file_path="test_basic.py")
    assert file_result["success"] == True
    assert file_result["exists"] == True
    print("âœ… æ–‡ä»¶å·¥å…·æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•ç»ˆç«¯å·¥å…·ï¼ˆç®€å•å‘½ä»¤ï¼‰
    terminal_result = tool_manager.execute_tool("terminal", command="echo 'test'")
    assert terminal_result["success"] == True
    assert "test" in terminal_result["stdout"]
    print("âœ… ç»ˆç«¯å·¥å…·æµ‹è¯•é€šè¿‡")
    
    print("âœ… å·¥å…·åŠŸèƒ½æµ‹è¯•å®Œæˆ\n")

def test_llm_client():
    """æµ‹è¯•å¤§æ¨¡å‹å®¢æˆ·ç«¯"""
    print("ğŸ¤– æµ‹è¯•å¤§æ¨¡å‹å®¢æˆ·ç«¯...")
    
    # ä½¿ç”¨é»˜è®¤é…ç½®
    config = Config.get_model_config("openai")
    client = LLMClient(config)
    
    # æµ‹è¯•æ¶ˆæ¯æ ¼å¼
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹"},
        {"role": "user", "content": "è¯·å›å¤ 'Hello'"}
    ]
    
    try:
        # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½ä¼šå› ä¸ºAPI Keyé—®é¢˜è€Œå¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        response = client.chat_completion(messages)
        print("âœ… å¤§æ¨¡å‹å®¢æˆ·ç«¯æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âš ï¸ å¤§æ¨¡å‹å®¢æˆ·ç«¯æµ‹è¯•è·³è¿‡ï¼ˆå¯èƒ½éœ€è¦API Keyï¼‰: {str(e)}")
    
    print("âœ… å¤§æ¨¡å‹å®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ\n")

def test_agent_initialization():
    """æµ‹è¯• Agent åˆå§‹åŒ–"""
    print("ğŸ¤– æµ‹è¯• Agent åˆå§‹åŒ–...")
    
    try:
        from agent import AIAgent
        
        # æµ‹è¯•åˆå§‹åŒ–ï¼ˆä¸å®é™…è°ƒç”¨APIï¼‰
        agent = AIAgent("openai")
        assert agent.model_config.provider == "openai"
        assert agent.tool_manager is not None
        print("âœ… Agent åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âš ï¸ Agent åˆå§‹åŒ–æµ‹è¯•è·³è¿‡: {str(e)}")
    
    print("âœ… Agent åˆå§‹åŒ–æµ‹è¯•å®Œæˆ\n")

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•...\n")
    
    try:
        test_config()
        test_tools()
        test_llm_client()
        test_agent_initialization()
        
        print("ğŸ‰ æ‰€æœ‰åŸºæœ¬åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        print("âœ… é¡¹ç›®æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main() 